# Copy from: https://github.com/NVlabs/MUNIT/tree/master/configs

# logger options
image_save_iter: 10000        # How often do you want to save output images during training
image_display_iter: 100       # How often do you want to display output images during training
display_size: 16              # How many images do you want to display each time
snapshot_save_iter: 10000     # How often do you want to save trained models
log_iter: 50                   # How often do you want to log the training stats

# optimization options
max_iter: 450000             # maximum number of training iterations
batch_size: 1                 # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.0                    # Adam parameter
beta2: 0.9                    # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr_d: 0.0004                  # initial d learning rate
lr_g: 0.0001                  # initial g learning rate
lr_policy: linear             # learning rate scheduler
decay_step: 400000
gan_w: 1                      # weight of adversarial loss
recon_x_w: 10                 # weight of image reconstruction loss
recon_s_w: 1                  # weight of style reconstruction loss
recon_c_w: 1                  # weight of content reconstruction loss
recon_x_cyc_w: 10             # weight of explicit style augmented cycle consistency loss
vgg_w: 0                      # weight of domain-invariant perceptual loss
sph_w: 10

# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  style_dim: 8                # length of style code
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder
  n_res: 4                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: sn                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 3                  # number of layers in D
  gan_type: hinge             # GAN loss [lsgan/nsgan]
  num_scales: 3               # number of scales
  pad_type: reflect           # padding type [zero/reflect]
sph:
  classnum: 227
  thd: 0.2875
  model_path: ./experiments/sphereface/outputs/init_1d741531e7a6424100e666465ba84a1a71a887d5/checkpoints/00011000.pth

# data options
input_dim_a: 3                              # number of image channels [1/3]
input_dim_b: 3                              # number of image channels [1/3]
num_workers: 4                              # number of data loading threads
new_size: 100                               # first resize the shortest image side to this size
crop_image_height: 112                      # random crop image of this height
crop_image_width: 96                        # random crop image of this width
data_root: ./datasets/WebCaricature/frontalization_dataset_v004    # dataset folder location
afid_path: ./datasets/WebCaricature/frontalization_dataset_v003/precaluC.npz
bfid_path: ./datasets/WebCaricature/frontalization_dataset_v003/precaluP.npz
